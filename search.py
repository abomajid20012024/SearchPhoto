# search.py
import torch
import numpy as np
import pickle
from PIL import Image
from torchvision import transforms
from sklearn.metrics.pairwise import cosine_similarity
from main import EmbeddingNet
import os

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = EmbeddingNet()
model.load_state_dict(torch.load("embedding_model.pth", map_location=DEVICE))
model.to(DEVICE)
model.eval()

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor()
])

def get_embedding(image_path):
    image = Image.open(image_path).convert("RGB")
    image = transform(image).unsqueeze(0).to(DEVICE)
    with torch.no_grad():
        embedding = model(image)
    return embedding.cpu().numpy()[0]

# ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
product_vectors = np.load("product_vectors.npy")
with open("product_paths.pkl", "rb") as f:
    product_paths = pickle.load(f)

# ØµÙˆØ±Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
query_image = "test_images/3.jpg"  # Ø¶Ø¹ Ù‡Ù†Ø§ Ø§Ù„Ù…Ø³Ø§Ø± Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
query_vector = get_embedding(query_image)

# Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡
similarities = cosine_similarity([query_vector], product_vectors)[0]
best_index = similarities.argmax()

# Ø§Ø³Ù… Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£Ù‚Ø±Ø¨
best_match_path = product_paths[best_index]
best_match_name = os.path.basename(best_match_path)
best_score = similarities[best_index]

# Ø¬Ù„Ø¨ Ø£ÙØ¶Ù„ 3 Ù…Ø¤Ø´Ø±Ø§Øª
top_k = 3
top_indices = similarities.argsort()[::-1][:top_k]

print(f"âœ… Ø£Ù‚Ø±Ø¨ {top_k} Ù…Ù†ØªØ¬Ø§Øª:")
for i, idx in enumerate(top_indices, 1):
    path = product_paths[idx]
    name = os.path.basename(path)
    score = similarities[idx]
    print(f"{i}. {name}  ğŸ”¢ Ø¯Ø±Ø¬Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡: {score:.4f}")
